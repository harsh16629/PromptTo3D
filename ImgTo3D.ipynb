{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ImgTo3D Prototype"
      ],
      "metadata": {
        "id": "VjrmcyeIGOdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the repo"
      ],
      "metadata": {
        "id": "syBcjO5uGXsu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60Ee_ieKGBhm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/openai/shap-e         # Clone repo\n",
        "%cd shap-e\n",
        "!pip install -e .                                   # Install necessary dependencies from the repo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "D3GosS7RGcqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "import torch\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
        "from shap_e.util.image_util import load_image"
      ],
      "metadata": {
        "id": "UZfS8nm4Gg7h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set device: GPU/CPU"
      ],
      "metadata": {
        "id": "QNDQd3KfGm1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')            # Use a dedicated GPU for better performance"
      ],
      "metadata": {
        "id": "s0ZNSrioGpLu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load models"
      ],
      "metadata": {
        "id": "Ga_6JsNwGql_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xm = load_model('transmitter', device=device)                   # Transimitter model; maps latent encodings into 3D space\n",
        "model = load_model('image300M', device=device)                  # Text encoding model; converts textual prompt to vector\n",
        "diffusion = diffusion_from_config(load_config('diffusion'))     # Core generative model"
      ],
      "metadata": {
        "id": "6WPIbI41GycE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main function"
      ],
      "metadata": {
        "id": "6Oh8TKbeG2Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from shap_e.util.notebooks import decode_latent_mesh\n",
        "\n",
        "# Main function to generate 3D models\n",
        "def imgTo3D(image_, size_=64, render_mode_ ='nerf'):\n",
        "  batch_size = 1\n",
        "  guidance_scale = 3.0                                        # Higher value results more precise output\n",
        "  image = image_\n",
        "\n",
        "  latents = sample_latents(\n",
        "      batch_size=batch_size,\n",
        "      model=model,\n",
        "      diffusion=diffusion,\n",
        "      guidance_scale=guidance_scale,\n",
        "      model_kwargs=dict(images=[image] * batch_size),         # Setting the conditioning prompt for all items in the batch\n",
        "      progress=True,                                          # Shows a progress bar\n",
        "      clip_denoised=True,                                     # Denoising for more coherent output\n",
        "      use_fp16=True,                                          # Uses 16-bit floating point instead of 32-bit for faster compute time\n",
        "      use_karras=True,                                        # Uses Karras sampling for better quality\n",
        "      karras_steps=64,                                        # Number of diffusion steps\n",
        "      sigma_min=1e-3,                                         # Starting noise level\n",
        "      sigma_max=160,                                          # Final noise level\n",
        "      s_churn=0,                                              # No additional stochastic noise added during sampling\n",
        "  )\n",
        "  render_mode = 'nerf'                                        # Rendering mode for the output images; 'nerf' or 'stf'\n",
        "  size = 64                                                   # Size of the renders; higher values take longer to render.\n",
        "\n",
        "  cameras = create_pan_cameras(size, device)\n",
        "\n",
        "  for i, latent in enumerate(latents):\n",
        "      images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
        "      display(gif_widget(images))\n",
        "\n",
        "\n",
        "  for i, latent in enumerate(latents):\n",
        "    t = decode_latent_mesh(xm, latent).tri_mesh()\n",
        "    with open(f'generated_mesh_{i}.stl', 'wb') as f:\n",
        "      t.write_ply(f)\n",
        "    with open(f'generated_mesh_{i}.obj', 'w') as f:\n",
        "      t.write_obj(f)"
      ],
      "metadata": {
        "id": "-4IPw1XeG4CC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test run"
      ],
      "metadata": {
        "id": "nCczCzTvG9VS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the best result, remove the background from the image, or use a plain background.\n",
        "image = load_image(\"/content/red_car.jpg\")\n",
        "\n",
        "imgTo3D(image)"
      ],
      "metadata": {
        "id": "ymbJXWFAG_zi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}