{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xov2yqWA94EL"
      },
      "source": [
        "# TextTo3D prototype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaV4w6lN-AnN"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "13fvmMKGrWDm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/openai/shap-e   #clone repo\n",
        "%cd shap-e\n",
        "!pip install -e .  #install necessary dependencies from the repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEkwEuHv-IUt"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS8FvgZwrkgr"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import torch\n",
        "from shap_e.diffusion.sample import sample_latents\n",
        "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
        "from shap_e.models.download import load_model, load_config\n",
        "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-x2_vEl-NZX"
      },
      "source": [
        "## Set device: GPU/CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbHKw9RY35ni"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')     #Use a dedicated GPU for better performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9PXS08S-S5l"
      },
      "source": [
        "## Load models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raP_q7G57W_W"
      },
      "outputs": [],
      "source": [
        "xm = load_model('transmitter', device=device)    #Transimitter model; maps latent encodings into 3D space\n",
        "model = load_model('text300M', device=device)    #Text encoding model; converts textual prompt to vector\n",
        "diffusion = diffusion_from_config(load_config('diffusion'))  #Core generative model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95HbU6Ra-Ypq"
      },
      "source": [
        "## Generate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d5wqEGv7dE0"
      },
      "outputs": [],
      "source": [
        "#Main function to generate 3D models\n",
        "def generate_3d(prompt_, size_=64, render_mode_ ='nerf'):  #size -> Number of camera views for output GIF (reduce for better performance)\n",
        "    batch_size = 1                                         \n",
        "    guidance_scale = 15.0                                  #Higher value results more precise output\n",
        "    prompt = prompt_                \n",
        "\n",
        "    latents = sample_latents(\n",
        "        batch_size=batch_size,\n",
        "        model=model,                                       \n",
        "        diffusion=diffusion,                               \n",
        "        guidance_scale=guidance_scale,\n",
        "        model_kwargs=dict(texts=[prompt] * batch_size),    #Setting the conditioning prompt for all items in the batch\n",
        "        progress=True,                                     #Shows a progress bar\n",
        "        clip_denoised=True,                                #Denoising for more coherent output\n",
        "        use_fp16=True,                                     #Uses 16-bit floating point instead of 32-bit for faster compute time\n",
        "        use_karras=True,                                   #Keras sampling for better denoising \n",
        "        karras_steps=64,                                   #Number of diffusion steps\n",
        "        sigma_min=1e-3,                                    #Starting noise level\n",
        "        sigma_max=160,                                     #Final noise level\n",
        "        s_churn=0)                                         #No additional stochastic noise added during sampling \n",
        "    render_mode = render_mode_\n",
        "    size = size_\n",
        "    cameras = create_pan_cameras(size, device)             #\n",
        "    \n",
        "    #Loop to display 3D gif \n",
        "    for i, latent in enumerate(latents):\n",
        "        images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
        "        display(gif_widget(images))\n",
        "    from shap_e.util.notebooks import decode_latent_mesh\n",
        "\n",
        "    #Loop to save the generated mesh\n",
        "    for i, latent in enumerate(latents):\n",
        "      t = decode_latent_mesh(xm, latent).tri_mesh()\n",
        "      with open(f'generated_mesh_{i}.stl', 'wb') as f:\n",
        "          t.write_ply(f)\n",
        "      with open(f'generated_mesh_{i}.obj', 'w') as f:\n",
        "          t.write_obj(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndc0eXEQ-dCp"
      },
      "source": [
        "## Test run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcJhOjoC7oBT"
      },
      "outputs": [],
      "source": [
        "generate_3d('red chair', 256)   #test run"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
